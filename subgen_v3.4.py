import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import threading, os, subprocess, tempfile, time
from datetime import timedelta
import torch, numpy as np
from faster_whisper import WhisperModel
import librosa, soundfile as sf

class SubGenerator:
    def __init__(self, root):
        self.root = root
        self.root.title("SubGenerator v3.4 - CUDA 11.7 Optimized (Fixed)")
        self.root.geometry("550x420")
        self.input_file = self.output_dir = ""
        self.start_time = self.model = None
        self.setup_ui()
    
    def setup_ui(self):
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.pack(fill='both', expand=True)
        
        ttk.Label(main_frame, text="SubGenerator v3.4", font=("Arial", 16, "bold")).pack(pady=(0, 10))
        ttk.Label(main_frame, text="CUDA 11.7 | GTX 1080Ti | faster-whisper 0.9.0 (Fixed)", font=("Arial", 9), foreground="blue").pack(pady=(0, 15))
        
        # –§–∞–π–ª
        file_frame = ttk.Frame(main_frame)
        file_frame.pack(fill='x', pady=5)
        ttk.Label(file_frame, text="–§–∞–π–ª:").pack(side='left')
        self.file_label = ttk.Label(file_frame, text="–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω", foreground="gray")
        self.file_label.pack(side='left', padx=(10, 0))
        ttk.Button(file_frame, text="–í—ã–±—Ä–∞—Ç—å", command=self.select_file).pack(side='right')
        
        # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        device_frame = ttk.Frame(main_frame)
        device_frame.pack(fill='x', pady=5)
        ttk.Label(device_frame, text="–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ:").pack(side='left')
        self.device_var = tk.StringVar(value="auto")
        self.device_combo = ttk.Combobox(device_frame, textvariable=self.device_var, state="readonly", width=35)
        self.device_combo.pack(side='left', padx=(10, 0))
        
        self.gpu_info_var = tk.StringVar()
        ttk.Label(main_frame, textvariable=self.gpu_info_var, foreground="green", font=("Arial", 8)).pack(pady=2)
        self.setup_device_options()
        
        # –ú–æ–¥–µ–ª—å
        model_frame = ttk.Frame(main_frame)
        model_frame.pack(fill='x', pady=5)
        ttk.Label(model_frame, text="–ú–æ–¥–µ–ª—å:").pack(side='left')
        self.model_var = tk.StringVar(value="base")
        model_combo = ttk.Combobox(model_frame, textvariable=self.model_var, state="readonly", width=20, values=["tiny", "base", "small", "medium"])
        model_combo.pack(side='left', padx=(10, 0))
        
        # VAD –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        vad_frame = ttk.Frame(main_frame)
        vad_frame.pack(fill='x', pady=5)
        ttk.Label(vad_frame, text="VAD —Ä–µ–∂–∏–º:").pack(side='left')
        self.vad_var = tk.StringVar(value="adaptive")
        vad_combo = ttk.Combobox(vad_frame, textvariable=self.vad_var, state="readonly", width=20, 
                                values=["adaptive", "conservative", "aggressive", "disabled"])
        vad_combo.pack(side='left', padx=(10, 0))
        
        # –ü–∞–ø–∫–∞
        output_frame = ttk.Frame(main_frame)
        output_frame.pack(fill='x', pady=5)
        ttk.Label(output_frame, text="–ü–∞–ø–∫–∞:").pack(side='left')
        self.output_label = ttk.Label(output_frame, text="–†—è–¥–æ–º —Å —Ñ–∞–π–ª–æ–º", foreground="gray")
        self.output_label.pack(side='left', padx=(10, 0))
        ttk.Button(output_frame, text="–í—ã–±—Ä–∞—Ç—å –ø–∞–ø–∫—É", command=self.select_output_dir).pack(side='right')
        
        # –ü—Ä–æ–≥—Ä–µ—Å—Å –∏ —Å—Ç–∞—Ç—É—Å
        self.progress_var = tk.DoubleVar()
        self.progress_bar = ttk.Progressbar(main_frame, variable=self.progress_var, maximum=100, length=450)
        self.progress_bar.pack(pady=15, fill='x')
        
        self.status_var = tk.StringVar(value="–ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
        ttk.Label(main_frame, textvariable=self.status_var).pack(pady=2)
        
        self.time_var = tk.StringVar(value="")
        ttk.Label(main_frame, textvariable=self.time_var, foreground="blue").pack(pady=2)
        
        self.start_button = ttk.Button(main_frame, text="–°–æ–∑–¥–∞—Ç—å —Å—É–±—Ç–∏—Ç—Ä—ã", command=self.start_processing)
        self.start_button.pack(pady=15)
        
        self.log_text = tk.Text(main_frame, height=8, wrap=tk.WORD)
        self.log_text.pack(fill='both', expand=True, pady=(10, 0))
    
    def setup_device_options(self):
        cuda_available = torch.cuda.is_available()
        if cuda_available:
            try:
                gpu_name = torch.cuda.get_device_name(0)
                major, minor = torch.cuda.get_device_capability(0)
                cuda_version = torch.version.cuda
                vram_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                
                device_options = [f"GPU: {gpu_name} (CC {major}.{minor}, CUDA {cuda_version}, {vram_gb:.1f}GB)", "CPU (–º–µ–¥–ª–µ–Ω–Ω–æ, –Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω–æ)"]
                self.device_var.set(device_options[0])
                self.gpu_info_var.set(f"‚úì {'GTX 1080Ti –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ - CUDA 11.7 —Ä–µ–∂–∏–º' if '1080' in gpu_name and f'{major}.{minor}' == '6.1' else f'GPU –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ - compute capability {major}.{minor}'}")
            except Exception as e:
                device_options = ["CPU (—Ç–æ–ª—å–∫–æ)", f"GPU –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {str(e)}"]
                self.device_var.set("CPU (—Ç–æ–ª—å–∫–æ)")
                self.gpu_info_var.set("‚ö† GPU –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        else:
            device_options = ["CPU (—Ç–æ–ª—å–∫–æ)"]
            self.device_var.set("CPU (—Ç–æ–ª—å–∫–æ)")
            self.gpu_info_var.set("‚ö† CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        
        self.device_combo['values'] = device_options
    
    def log_message(self, message):
        timestamp = time.strftime("%H:%M:%S")
        self.log_text.insert(tk.END, f"[{timestamp}] {message}\n")
        self.log_text.see(tk.END)
        self.root.update_idletasks()
    
    def update_time_estimate(self, current_progress, stage_name=""):
        if self.start_time and current_progress > 5:
            elapsed = time.time() - self.start_time
            if current_progress > 0:
                total_estimated = (elapsed / current_progress) * 100
                remaining = max(0, total_estimated - elapsed)
                elapsed_str = str(timedelta(seconds=int(elapsed)))
                remaining_str = str(timedelta(seconds=int(remaining)))
                self.time_var.set(f"–ü—Ä–æ—à–ª–æ: {elapsed_str} | –û—Å—Ç–∞–ª–æ—Å—å: ~{remaining_str} | {stage_name}")
    
    def select_file(self):
        filename = filedialog.askopenfilename(title='–í—ã–±–µ—Ä–∏—Ç–µ –∞—É–¥–∏–æ –∏–ª–∏ –≤–∏–¥–µ–æ —Ñ–∞–π–ª',
            filetypes=[('–ê—É–¥–∏–æ –∏ –≤–∏–¥–µ–æ', '*.wav *.mp4 *.avi *.mkv *.mov *.mp3 *.flac *.m4a *.webm')])
        if filename:
            self.input_file = filename
            self.file_label.config(text=os.path.basename(filename), foreground="black")
    
    def select_output_dir(self):
        directory = filedialog.askdirectory(title='–í—ã–±–µ—Ä–∏—Ç–µ –ø–∞–ø–∫—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è')
        if directory:
            self.output_dir = directory
            self.output_label.config(text=directory, foreground="black")
    
    def start_processing(self):
        if not self.input_file:
            messagebox.showerror("–û—à–∏–±–∫–∞", "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª!")
            return
        self.start_button.config(state="disabled")
        self.start_time = time.time()
        threading.Thread(target=self.process_file, daemon=True).start()
    
    def extract_audio_optimized(self, video_path, output_path):
        try:
            self.log_message("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ (16kHz, mono)...")
            # –£–ª—É—á—à–µ–Ω–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ FFmpeg —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π —à—É–º–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π
            cmd = [
                'ffmpeg', '-i', video_path, 
                '-vn',  # –¢–æ–ª—å–∫–æ –∞—É–¥–∏–æ
                '-acodec', 'pcm_s16le',  # 16-bit PCM
                '-ar', '16000',  # 16kHz
                '-ac', '1',  # mono
                '-af', 'highpass=f=80,lowpass=f=8000,volume=1.2',  # –§–∏–ª—å—Ç—Ä—ã –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
                '-y', output_path
            ]
            result = subprocess.run(cmd, check=True, capture_output=True, text=True)
            self.log_message("‚úì –ê—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π")
            return True
        except subprocess.CalledProcessError as e:
            self.log_message(f"–û—à–∏–±–∫–∞ FFmpeg: {e.stderr}")
            return False
        except Exception as e:
            self.log_message(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞—É–¥–∏–æ: {e}")
            return False
    
    def get_device_settings(self):
        device_text = self.device_var.get()
        return ("cpu", "int8") if "CPU" in device_text or not torch.cuda.is_available() else ("cuda", "int8_float32")
    
    def get_vad_parameters(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã VAD –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞"""
        vad_mode = self.vad_var.get()
        
        if vad_mode == "disabled":
            return None
        elif vad_mode == "conservative":
            return dict(
                threshold=0.3,
                min_speech_duration_ms=100,
                max_speech_duration_s=30,
                min_silence_duration_ms=200,
                window_size_samples=512,
                speech_pad_ms=200
            )
        elif vad_mode == "aggressive":
            return dict(
                threshold=0.7,
                min_speech_duration_ms=50,
                max_speech_duration_s=15,
                min_silence_duration_ms=100,
                window_size_samples=256,
                speech_pad_ms=100
            )
        else:  # adaptive (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
            return dict(
                threshold=0.5,
                min_speech_duration_ms=250,
                max_speech_duration_s=20,
                min_silence_duration_ms=300,
                window_size_samples=1024,
                speech_pad_ms=300
            )
    
    def load_whisper_model(self):
        try:
            device, compute_type = self.get_device_settings()
            model_size = self.model_var.get()
            self.log_message(f"–ó–∞–≥—Ä—É–∑–∫–∞ faster-whisper {model_size} –º–æ–¥–µ–ª–∏...")
            self.log_message(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}, —Ç–∏–ø: {compute_type}")
            
            model_params = {
                'model_size_or_path': model_size,
                'device': device,
                'compute_type': compute_type,
                'num_workers': 1,
                'download_root': None,
                'local_files_only': False
            }
            
            if device == "cuda":
                model_params['cpu_threads'] = 4
            else:
                model_params['cpu_threads'] = 8
            
            self.model = WhisperModel(**model_params)
            self.log_message("‚úì –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            return True
        except Exception as e:
            self.log_message(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {str(e)}")
            return False
    
    def clean_transcription_artifacts(self, word_timings):
        """–û—á–∏—â–∞–µ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Ç–∏–ø–∞ '–ê–ê–ê–ê' –∏ '—ç—ç—ç—ç—ç'"""
        cleaned_words = []
        
        for word_data in word_timings:
            word = word_data['word'].strip()
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —è–≤–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
            if self.is_transcription_artifact(word):
                self.log_message(f"üßπ –£–¥–∞–ª–µ–Ω –∞—Ä—Ç–µ—Ñ–∞–∫—Ç: '{word}' ({word_data['start']:.1f}s)")
                continue
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            if word_data.get('probability', 1.0) < 0.3:
                self.log_message(f"üßπ –£–¥–∞–ª–µ–Ω–æ —Å–ª–æ–≤–æ —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é: '{word}' (p={word_data.get('probability', 0):.2f})")
                continue
            
            cleaned_words.append(word_data)
        
        return cleaned_words
    
    def is_transcription_artifact(self, word):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"""
        word_lower = word.lower().strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Å–∏–º–≤–æ–ª—ã
        if len(word_lower) > 3:
            unique_chars = set(word_lower)
            if len(unique_chars) <= 2:  # –°–ª–æ–≤–æ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ 1-2 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
                return True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
        for char in ['–∞', '—ç', '–æ', '—É', '–∏', '—ã', '–µ', 'm', 'n', 'h']:
            if word_lower.count(char) > 4:
                return True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
        artifacts = [
            '–∞–∞–∞–∞–∞', '—ç—ç—ç—ç—ç', '–æ–æ–æ–æ–æ', '—É—É—É—É—É', '–º–º–º–º–º',
            '–Ω–Ω–Ω–Ω', '—Ö–º–º–º', '—ç–º–º', '–∞–º–º', '—É–≥—É', '–º–≥–º'
        ]
        
        if word_lower in artifacts or any(artifact in word_lower for artifact in artifacts):
            return True
        
        return False
    
    def transcribe_with_word_timestamps(self, audio_path):
        try:
            if not self.model and not self.load_whisper_model():
                return []
            
            self.log_message("–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏...")
            self.progress_var.set(35)
            self.update_time_estimate(35, "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏")
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã VAD
            vad_params = self.get_vad_parameters()
            vad_enabled = vad_params is not None
            
            self.log_message(f"VAD —Ä–µ–∂–∏–º: {self.vad_var.get()} {'(–≤–∫–ª—é—á–µ–Ω)' if vad_enabled else '(–æ—Ç–∫–ª—é—á–µ–Ω)'}")
            
            # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
            transcribe_params = {
                'audio': audio_path,
                'language': 'ru',
                'word_timestamps': True,
                'beam_size': 5,
                'best_of': 5,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
                'temperature': [0.0, 0.2, 0.4],  # –ú–Ω–æ–≥–æ—Å—Ç—É–ø–µ–Ω—á–∞—Ç–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞
                'condition_on_previous_text': True,  # –í–∫–ª—é—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                'compression_ratio_threshold': 2.4,
                'no_speech_threshold': 0.6,
                'initial_prompt': "–≠—Ç–æ —Ä—É—Å—Å–∫–∞—è —Ä–µ—á—å. –ò–∑–±–µ–≥–∞–π—Ç–µ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è –∑–≤—É–∫–æ–≤ –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤.",
                'vad_filter': vad_enabled
            }
            
            if vad_enabled:
                transcribe_params['vad_parameters'] = vad_params
            
            segments, info = self.model.transcribe(**transcribe_params)
            
            self.progress_var.set(70)
            self.update_time_estimate(70, "–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            
            word_timings = []
            total_segments = 0
            processed_segments = 0
            
            for segment in segments:
                total_segments += 1
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–∞
                if hasattr(segment, 'avg_logprob') and segment.avg_logprob < -1.5:
                    self.log_message(f"‚ö† –ü—Ä–æ–ø—É—â–µ–Ω —Å–µ–≥–º–µ–Ω—Ç —Å –Ω–∏–∑–∫–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º: {segment.start:.1f}s-{segment.end:.1f}s")
                    continue
                
                processed_segments += 1
                
                if hasattr(segment, 'words') and segment.words:
                    for word in segment.words:
                        if hasattr(word, 'word') and hasattr(word, 'start') and hasattr(word, 'end'):
                            word_timings.append({
                                "word": word.word.strip(),
                                "start": word.start,
                                "end": word.end,
                                "probability": getattr(word, 'probability', 0.8)
                            })
                else:
                    # Fallback –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –±–µ–∑ word timestamps
                    text = segment.text.strip()
                    if text and len(text) > 0:
                        words = text.split()
                        if words:
                            duration = segment.end - segment.start
                            word_duration = duration / len(words)
                            for i, word in enumerate(words):
                                word_start = segment.start + (i * word_duration)
                                word_timings.append({
                                    "word": word,
                                    "start": word_start,
                                    "end": word_start + word_duration,
                                    "probability": 0.7
                                })
            
            # –û—á–∏—â–∞–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
            original_count = len(word_timings)
            word_timings = self.clean_transcription_artifacts(word_timings)
            cleaned_count = len(word_timings)
            
            self.log_message(f"‚úì –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {total_segments} (–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_segments})")
            self.log_message(f"‚úì –ò–∑–≤–ª–µ—á–µ–Ω–æ —Å–ª–æ–≤: {original_count} (–ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {cleaned_count})")
            self.log_message(f"‚úì –£–¥–∞–ª–µ–Ω–æ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤: {original_count - cleaned_count}")
            self.log_message(f"‚úì –Ø–∑—ã–∫: {info.language} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {info.language_probability:.2f})")
            
            return word_timings
            
        except Exception as e:
            self.log_message(f"‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {str(e)}")
            return []
    
    def format_time(self, seconds):
        td = timedelta(seconds=seconds)
        hours, remainder = divmod(td.total_seconds(), 3600)
        minutes, seconds = divmod(remainder, 60)
        milliseconds = int((seconds % 1) * 1000)
        return f"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d},{milliseconds:03d}"
    
    def create_srt_file(self, word_timings, output_path):
        try:
            self.log_message("–°–æ–∑–¥–∞–Ω–∏–µ SRT —Ñ–∞–π–ª–∞...")
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
            word_timings.sort(key=lambda x: x['start'])
            
            with open(output_path, 'w', encoding='utf-8') as f:
                for i, word_data in enumerate(word_timings, 1):
                    start = self.format_time(word_data['start'])
                    end = self.format_time(word_data['end'])
                    word = word_data['word'].strip()
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –ø—Ä–∏ –∑–∞–ø–∏—Å–∏
                    if not self.is_transcription_artifact(word) and len(word) > 0:
                        f.write(f"{i}\n{start} --> {end}\n{word}\n\n")
            
            return True
        except Exception as e:
            self.log_message(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è SRT: {str(e)}")
            return False
    
    def process_file(self):
        try:
            self.status_var.set("–û–±—Ä–∞–±–æ—Ç–∫–∞...")
            self.progress_var.set(0)
            
            base_name = os.path.splitext(os.path.basename(self.input_file))[0]
            output_dir = self.output_dir if self.output_dir else os.path.dirname(self.input_file)
            output_path = os.path.join(output_dir, f"{base_name}_fixed.srt")
            
            file_ext = os.path.splitext(self.input_file)[1].lower()
            audio_extensions = ['.wav', '.mp3', '.flac', '.m4a', '.ogg']
            video_extensions = ['.mp4', '.avi', '.mkv', '.mov', '.webm']
            cleanup_files = []
            
            if file_ext in video_extensions or (file_ext in audio_extensions and file_ext != '.wav'):
                temp_audio = os.path.join(output_dir, f"temp_{base_name}_processed.wav")
                if not self.extract_audio_optimized(self.input_file, temp_audio):
                    raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å/–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ")
                audio_path = temp_audio
                cleanup_files = [temp_audio]
            elif file_ext in audio_extensions:
                audio_path = self.input_file
            else:
                raise Exception(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {file_ext}")
            
            self.progress_var.set(15)
            self.update_time_estimate(15, "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∞—É–¥–∏–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            
            if not self.model and not self.load_whisper_model():
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å Whisper")
            
            self.progress_var.set(25)
            self.update_time_estimate(25, "–ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞")
            
            word_timings = self.transcribe_with_word_timestamps(audio_path)
            if not word_timings:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å –∏–ª–∏ –∏–∑–≤–ª–µ—á—å —Å–ª–æ–≤–∞")
            
            self.progress_var.set(85)
            self.update_time_estimate(85, "–°–æ–∑–¥–∞–Ω–∏–µ —Å—É–±—Ç–∏—Ç—Ä–æ–≤")
            
            if not self.create_srt_file(word_timings, output_path):
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å SRT —Ñ–∞–π–ª")
            
            # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            for temp_file in cleanup_files:
                if os.path.exists(temp_file):
                    try:
                        os.unlink(temp_file)
                        self.log_message(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {os.path.basename(temp_file)}")
                    except:
                        pass
            
            self.progress_var.set(100)
            self.status_var.set("–ì–æ—Ç–æ–≤–æ!")
            
            total_time = time.time() - self.start_time
            total_time_str = str(timedelta(seconds=int(total_time)))
            
            self.time_var.set(f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞: {total_time_str}")
            self.log_message(f"‚úÖ SRT —Å–æ–∑–¥–∞–Ω: {output_path}")
            self.log_message(f"üìä –í—Å–µ–≥–æ —Å–ª–æ–≤: {len(word_timings)}")
            self.log_message(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_time_str}")
            
            probabilities = [w.get('probability', 0) for w in word_timings if w.get('probability')]
            if probabilities:
                avg_confidence = sum(probabilities) / len(probabilities)
                self.log_message(f"üìà –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_confidence:.2f}")
            
            messagebox.showinfo("–£—Å–ø–µ—Ö", f"SRT —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω!\n{output_path}\n\n–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(word_timings)}\n–í—Ä–µ–º—è: {total_time_str}\n–ú–æ–¥–µ–ª—å: {self.model_var.get()}\nVAD: {self.vad_var.get()}")
            
        except Exception as e:
            self.status_var.set("–û—à–∏–±–∫–∞")
            self.time_var.set("")
            self.log_message(f"‚ùå –û–®–ò–ë–ö–ê: {str(e)}")
            messagebox.showerror("–û—à–∏–±–∫–∞", str(e))
        finally:
            self.start_button.config(state="normal")

def main():
    print("=== SubGenerator v3.4 - System Check (Fixed Version) ===")
    print(f"PyTorch: {torch.__version__}")
    print(f"CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}")
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"VRAM: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f}GB")
        major, minor = torch.cuda.get_device_capability(0)
        print(f"Compute Capability: {major}.{minor}")
    print("========================================================")
    
    root = tk.Tk()
    app = SubGenerator(root)
    root.mainloop()

if __name__ == "__main__":
    main()